{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLab Cup 4: Recommender Systems\n",
    "- Team name: 瑜旋學姊教我DL\n",
    "- Team members:\n",
    "    - 王興彥 112062531\n",
    "    - 邱仁緯 112062559\n",
    "    - 林沁璿 112062632"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from evaluation.environment import TrainingEnvironment, TestingEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official hyperparameters for this competition (do not modify)\n",
    "N_TRAIN_USERS = 1000\n",
    "N_TEST_USERS = 2000\n",
    "N_ITEMS = 209527\n",
    "HORIZON = 2000\n",
    "TEST_EPISODES = 5\n",
    "SLATE_SIZE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "USER_DATA = os.path.join('dataset', 'user_data.json')\n",
    "ITEM_DATA = os.path.join('dataset', 'item_data.json')\n",
    "\n",
    "# Output file path\n",
    "OUTPUT_PATH = os.path.join('output', 'output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_json(USER_DATA, lines=True)\n",
    "# df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = pd.read_json(ITEM_DATA, lines=True)\n",
    "# df_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_USERS = 2000\n",
    "N_ITEMS = 209527\n",
    "SEED = 0\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ratings = pd.DataFrame(columns=['user_id', 'item_id', 'rating'])\n",
    "\n",
    "# ratings_data = []\n",
    "# for i in range(N_TRAIN_USERS):\n",
    "#     for item_id in df_user['history'][i][:3]:\n",
    "#         ratings_data.append({'user_id': i, 'item_id': item_id, 'rating': 5.0})\n",
    "\n",
    "# df_ratings = pd.DataFrame(ratings_data)\n",
    "\n",
    "df_ratings = pd.read_csv('./dataset/ratings_pos.csv')\n",
    "# df_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunkSVDRecommender(tf.keras.Model):\n",
    "    '''\n",
    "    Simplified Funk-SVD recommender model\n",
    "    '''\n",
    "    def __init__(self, m_users: int, n_items: int, embedding_size: int, learning_rate: float):\n",
    "        '''\n",
    "        Constructor of the model\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.m = m_users\n",
    "        self.n = n_items\n",
    "        self.k = embedding_size\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # user embeddings P\n",
    "        self.P = tf.Variable(tf.keras.initializers.RandomNormal()(shape=(self.m, self.k)))\n",
    "\n",
    "        # item embeddings Q\n",
    "        self.Q = tf.Variable(tf.keras.initializers.RandomNormal()(shape=(self.n, self.k)))\n",
    "\n",
    "        # optimizer\n",
    "        self.optimizer = tf.optimizers.Adam(learning_rate=self.lr)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, user_ids: tf.Tensor, item_ids: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Forward pass used in training and validating\n",
    "        '''\n",
    "        # dot product the user and item embeddings corresponding to the observed interaction pairs to produce predictions\n",
    "        y_pred = tf.reduce_sum(tf.gather(self.P, indices=user_ids) * tf.gather(self.Q, indices=item_ids), axis=1)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    @tf.function\n",
    "    def compute_loss(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Compute the MSE loss of the model\n",
    "        '''\n",
    "        loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Train the model with one batch\n",
    "        data: batched user-item interactions\n",
    "        each record in data is in the format ['user_id', 'item_id', 'rating']\n",
    "        '''\n",
    "        user_ids = tf.cast(data[:, 0], dtype=tf.int32)\n",
    "        item_ids = tf.cast(data[:, 1], dtype=tf.int32)\n",
    "        y_true = tf.cast(data[:, 2], dtype=tf.float32)\n",
    "\n",
    "        # slate = self.eval_predict_onestep(user_ids)\n",
    "        # print(slate)\n",
    "        # compute loss\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(user_ids, item_ids)\n",
    "            loss = self.compute_loss(y_true, y_pred)\n",
    "\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        # update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def val_step(self, data: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Validate the model with one batch\n",
    "        data: batched user-item interactions\n",
    "        each record in data is in the format ['user_id', 'item_id', 'rating']\n",
    "        '''\n",
    "        user_ids = tf.cast(data[:, 0], dtype=tf.int32)\n",
    "        item_ids = tf.cast(data[:, 1], dtype=tf.int32)\n",
    "        y_true = tf.cast(data[:, 2], dtype=tf.float32)\n",
    "\n",
    "        # compute loss\n",
    "        y_pred = self(user_ids, item_ids)\n",
    "        loss = self.compute_loss(y_true, y_pred)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def eval_predict_onestep(self, query: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Retrieve and return the MovieIDs of the 5 recommended movies given a query\n",
    "        You should return a tf.Tensor with shape=(5,)\n",
    "        query will be a tf.Tensor with shape=(1,) and dtype=tf.int64\n",
    "        query is the UserID of the query\n",
    "        '''\n",
    "        # dot product the selected user and all item embeddings to produce predictions\n",
    "        user_id = tf.cast(query, tf.int32)\n",
    "        y_pred = tf.reduce_sum(tf.gather(self.P, user_id) * self.Q, axis=1)\n",
    "\n",
    "        # select the top 5 items with highest scores in y_pred\n",
    "        y_top_5 = tf.math.top_k(y_pred, k=5).indices\n",
    "\n",
    "        return y_top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4245.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# let interactions with rating >= 3 be positive interactions\n",
    "POSITIVE_THRESHOLD = 3\n",
    "\n",
    "# each per-user validation set should contain at least 3 positive interactions\n",
    "POSITIVE_PER_USER = 4\n",
    "\n",
    "train_dataframes = []\n",
    "val_dataframes = []\n",
    "# ['user_id', 'item_id', 'rating']\n",
    "for i in tqdm(range(N_TRAIN_USERS)):\n",
    "    user_all = df_ratings[df_ratings['user_id'] == i]\n",
    "    user_positive = user_all[user_all['rating'] >= POSITIVE_THRESHOLD]\n",
    "\n",
    "    # check if there are enough positive interactions to build a validation set for this user\n",
    "    if len(user_positive) >= POSITIVE_PER_USER:\n",
    "        split_idx = user_positive.iloc[-POSITIVE_PER_USER].name\n",
    "        user_train = user_all.loc[:split_idx]\n",
    "        user_test = user_all.loc[split_idx:]\n",
    "        # assert user_train['Timestamp'].max() <= user_test['Timestamp'].min()\n",
    "        train_dataframes.append(user_train)\n",
    "        val_dataframes.append(user_test)\n",
    "    else:\n",
    "        train_dataframes.append(user_all)\n",
    "\n",
    "# concat all per-user training sets\n",
    "df_train = pd.concat(train_dataframes)\n",
    "\n",
    "# normalize the ratings (may be beneficial to some models)\n",
    "df_train_norm = df_train\n",
    "df_train_norm['rating'] -= 3\n",
    "df_train_norm['rating'] /= 2\n",
    "\n",
    "# concat all per-user validation sets\n",
    "df_val = pd.concat(val_dataframes)\n",
    "\n",
    "# normalize the ratings (may be beneficial to some models)\n",
    "# here we make a copy of the un-normalized validation set for evaluation\n",
    "df_val_norm = df_val.copy(deep=True)\n",
    "df_val_norm['rating'] -= 3\n",
    "df_val_norm['rating'] /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "EMBEDDING_SIZE = 512\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# prepare datasets\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(df_train_norm)\n",
    "dataset_train = dataset_train.batch(batch_size=BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices(df_val_norm)\n",
    "dataset_val = dataset_val.batch(batch_size=BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# build the model\n",
    "model = FunkSVDRecommender(m_users=N_TRAIN_USERS, n_items=N_ITEMS, embedding_size=EMBEDDING_SIZE, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(epoch=tf.Variable(0), net=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, './ckpts/FSVD', max_to_keep=10, checkpoint_name='fsvd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f52ac7ad630>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.restore(manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1271 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705370569.151663   10307 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "Training: 100%|██████████| 1271/1271 [00:10<00:00, 120.35it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 549.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train_loss: 0.1272, val_loss: 0.7911\n",
      "\n",
      "Saved checkpoint for epoch 81: ./ckpts/FSVD/fsvd-81\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 159.64it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 2061.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train_loss: 0.1204, val_loss: 0.7892\n",
      "\n",
      "Saved checkpoint for epoch 82: ./ckpts/FSVD/fsvd-82\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 161.09it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 3076.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train_loss: 0.1138, val_loss: 0.7874\n",
      "\n",
      "Saved checkpoint for epoch 83: ./ckpts/FSVD/fsvd-83\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 159.33it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 2949.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train_loss: 0.1075, val_loss: 0.7857\n",
      "\n",
      "Saved checkpoint for epoch 84: ./ckpts/FSVD/fsvd-84\n",
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 160.21it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 3005.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train_loss: 0.1014, val_loss: 0.7840\n",
      "\n",
      "Saved checkpoint for epoch 85: ./ckpts/FSVD/fsvd-85\n",
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 159.47it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 2962.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train_loss: 0.0955, val_loss: 0.7823\n",
      "\n",
      "Saved checkpoint for epoch 86: ./ckpts/FSVD/fsvd-86\n",
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 160.49it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 3280.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train_loss: 0.0899, val_loss: 0.7807\n",
      "\n",
      "Saved checkpoint for epoch 87: ./ckpts/FSVD/fsvd-87\n",
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 160.64it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 3039.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train_loss: 0.0845, val_loss: 0.7791\n",
      "\n",
      "Saved checkpoint for epoch 88: ./ckpts/FSVD/fsvd-88\n",
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 159.85it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 1997.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train_loss: 0.0793, val_loss: 0.7776\n",
      "\n",
      "Saved checkpoint for epoch 89: ./ckpts/FSVD/fsvd-89\n",
      "Epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 160.49it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 3526.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train_loss: 0.0744, val_loss: 0.7761\n",
      "\n",
      "Saved checkpoint for epoch 90: ./ckpts/FSVD/fsvd-90\n",
      "Epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 160.89it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 2351.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 train_loss: 0.0697, val_loss: 0.7747\n",
      "\n",
      "Saved checkpoint for epoch 91: ./ckpts/FSVD/fsvd-91\n",
      "Epoch 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 160.15it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 2991.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 train_loss: 0.0652, val_loss: 0.7733\n",
      "\n",
      "Saved checkpoint for epoch 92: ./ckpts/FSVD/fsvd-92\n",
      "Epoch 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 160.58it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 2212.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 train_loss: 0.0609, val_loss: 0.7720\n",
      "\n",
      "Saved checkpoint for epoch 93: ./ckpts/FSVD/fsvd-93\n",
      "Epoch 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 160.21it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 2500.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 train_loss: 0.0569, val_loss: 0.7707\n",
      "\n",
      "Saved checkpoint for epoch 94: ./ckpts/FSVD/fsvd-94\n",
      "Epoch 15:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 161.83it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 3218.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 train_loss: 0.0530, val_loss: 0.7695\n",
      "\n",
      "Saved checkpoint for epoch 95: ./ckpts/FSVD/fsvd-95\n",
      "Epoch 16:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 161.45it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 3167.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 train_loss: 0.0494, val_loss: 0.7683\n",
      "\n",
      "Saved checkpoint for epoch 96: ./ckpts/FSVD/fsvd-96\n",
      "Epoch 17:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 159.65it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 3213.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 train_loss: 0.0459, val_loss: 0.7671\n",
      "\n",
      "Saved checkpoint for epoch 97: ./ckpts/FSVD/fsvd-97\n",
      "Epoch 18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 160.02it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 3294.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 train_loss: 0.0426, val_loss: 0.7661\n",
      "\n",
      "Saved checkpoint for epoch 98: ./ckpts/FSVD/fsvd-98\n",
      "Epoch 19:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 160.99it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 2110.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 train_loss: 0.0395, val_loss: 0.7650\n",
      "\n",
      "Saved checkpoint for epoch 99: ./ckpts/FSVD/fsvd-99\n",
      "Epoch 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1271/1271 [00:07<00:00, 159.97it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 3057.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 train_loss: 0.0366, val_loss: 0.7640\n",
      "\n",
      "Saved checkpoint for epoch 100: ./ckpts/FSVD/fsvd-100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    print(f'Epoch {epoch}:')\n",
    "    ckpt.epoch.assign_add(1)\n",
    "\n",
    "    # training\n",
    "    for data in tqdm(dataset_train, desc='Training'):\n",
    "        loss = model.train_step(data)\n",
    "        train_loss.append(loss.numpy())\n",
    "\n",
    "    # validating\n",
    "    for data in tqdm(dataset_val, desc='Validating'):\n",
    "        loss = model.val_step(data)\n",
    "        val_loss.append(loss.numpy())\n",
    "\n",
    "    # record losses\n",
    "    avg_train_loss = np.mean(train_loss)\n",
    "    avg_val_loss = np.mean(val_loss)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # print losses\n",
    "    print(f'Epoch {epoch} train_loss: {avg_train_loss:.4f}, val_loss: {avg_val_loss:.4f}\\n')\n",
    "    save_path = manager.save()\n",
    "    print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.epoch), save_path))  \n",
    "\n",
    "# plot the training curve\n",
    "plt.plot(train_losses, label='train_loss')\n",
    "plt.plot(val_losses, label='val_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 3it [00:00, 24.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function FunkSVDRecommender.eval_predict_onestep at 0x7f525bef8670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function FunkSVDRecommender.eval_predict_onestep at 0x7f525bef8670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 14215it [01:53, 124.83it/s]\n",
      "Testing: 14198it [01:41, 140.20it/s]\n",
      "Testing: 14209it [01:39, 142.10it/s]\n",
      "Testing: 14195it [01:40, 141.75it/s]\n",
      "Testing: 14222it [01:40, 141.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  avg_score\n",
       "0           0     0.0042\n",
       "1           1     0.0043\n",
       "2           2     0.0043\n",
       "3           3     0.0047\n",
       "4           4     0.0049\n",
       "...       ...        ...\n",
       "1995     1995     0.0025\n",
       "1996     1996     0.0025\n",
       "1997     1997     0.0025\n",
       "1998     1998     0.0025\n",
       "1999     1999     0.0025\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the testing environment\n",
    "test_env = TestingEnvironment()\n",
    "scores = []\n",
    "\n",
    "# The item_ids here is for the random recommender\n",
    "item_ids = [i for i in range(N_ITEMS)]\n",
    "\n",
    "# Repeat the testing process for 5 times\n",
    "for _ in range(TEST_EPISODES):\n",
    "    # [TODO] Load your model weights here (in the beginning of each testing episode)\n",
    "    # [TODO] Code for loading your model weights...\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "\n",
    "    # Start the testing process\n",
    "    with tqdm(desc='Testing') as pbar:\n",
    "        # Run as long as there exist some active users\n",
    "        while test_env.has_next_state():\n",
    "            # Get the current user id\n",
    "            cur_user = test_env.get_state()\n",
    "            \n",
    "            # [TODO] Employ your recommendation policy to generate a slate of 5 distinct items\n",
    "            # [TODO] Code for generating the recommended slate...\n",
    "            slate = model.eval_predict_onestep(cur_user)\n",
    "\n",
    "            # Get the response of the slate from the environment\n",
    "            clicked_id, in_environment = test_env.get_response(slate)\n",
    "\n",
    "            # [TODO] Update your model here (optional)\n",
    "            # [TODO] You can update your model at each step, or perform a batched update after some interval\n",
    "            # [TODO] Code for updating your model...\n",
    "            ratings_data = []\n",
    "            if clicked_id != -1:\n",
    "                ratings_data.append({'user_id': cur_user, 'item_id': clicked_id, 'rating': 5.0})\n",
    "            \n",
    "            df = pd.DataFrame(ratings_data)\n",
    "            df_ratings = pd.concat([df_ratings, df], ignore_index=True)\n",
    "            \n",
    "            # Update the progress indicator\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Record the score of this testing episode\n",
    "    scores.append(test_env.get_score())\n",
    "\n",
    "    # Reset the testing environment\n",
    "    test_env.reset()\n",
    "\n",
    "    # [TODO] Delete or reset your model weights here (in the end of each testing episode)\n",
    "    # [TODO] Code for deleting your model weights...\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    df_ratings = df_ratings.drop_duplicates(subset=['user_id', 'item_id'], keep='first', ignore_index=True)\n",
    "\n",
    "# Calculate the average scores \n",
    "avg_scores = [np.average(score) for score in zip(*scores)]\n",
    "\n",
    "# Generate a DataFrame to output the result in a .csv file\n",
    "df_result = pd.DataFrame([[user_id, avg_score] for user_id, avg_score in enumerate(avg_scores)], columns=['user_id', 'avg_score'])\n",
    "df_result.to_csv(OUTPUT_PATH, index=False)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10162.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13353.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33127.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35130.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>39676.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164955</th>\n",
       "      <td>1998.0</td>\n",
       "      <td>55561.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164956</th>\n",
       "      <td>1998.0</td>\n",
       "      <td>60372.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164957</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>77906.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164958</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>124792.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164959</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>125409.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164967 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id   item_id  rating\n",
       "0           0.0   10162.0     5.0\n",
       "1           0.0   13353.0     5.0\n",
       "2           0.0   33127.0     5.0\n",
       "3           0.0   35130.0     5.0\n",
       "4           0.0   39676.0     5.0\n",
       "...         ...       ...     ...\n",
       "164955   1998.0   55561.0     5.0\n",
       "164956   1998.0   60372.0     5.0\n",
       "164957   1999.0   77906.0     5.0\n",
       "164958   1999.0  124792.0     5.0\n",
       "164959   1999.0  125409.0     5.0\n",
       "\n",
       "[164967 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = df_ratings.sort_values(by=['user_id', 'item_id'])\n",
    "df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.996448\n"
     ]
    }
   ],
   "source": [
    "mae = (df_result['avg_score'] - 1).abs().mean()\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "### I. Models have tried during the competition.\n",
    "- **FunkSVD(from Recommender Systems Tutorial)**\n",
    "    The Funk Singular Value Decomposition (FunkSVD) model is a matrix factorization technique particularly suited for recommender systems. Unlike traditional SVD, FunkSVD can handle sparse matrices, which are typical in user-item interaction data. We selected the FunkSVD model due to its efficiency in dealing with sparse data and its proven track record in collaborative filtering tasks. Its ability to capture latent factors in user-item interactions makes it adept at predicting user preferences, even with limited interaction history. \n",
    "\n",
    "- **Item-Based Collaborative Filtering(failed)**\n",
    "    This model relies on the similarity between items to make recommendations. It constructs an item-item similarity matrix by computing the cosine similarity between item vectors in the user-item interaction matrix. Recommendations are then made based on items that are most similar to those the user has previously interacted with.Item-based collaborative filtering was chosen for its scalability and effectiveness in situations with fewer user interactions. We chose Item-Based Collaborative Filtering for its effectiveness in scenarios where user interactions are sparse and its inherent scalability when handling large user bases. This method appeared particularly suitable for our dataset, which had a higher item-to-user ratio. The primary challenge was the sheer volume of items in our dataset, which led to an excessively large item-item similarity matrix. This matrix size posed memory constraints, exceeding our available computational resources.\n",
    "\n",
    "### II. List the experiments you have done.\n",
    "- **FunkSVD**\n",
    "    - Interaction Data Processing: Our initial approach involved using interaction data to determine whether a user clicked on an item. We assigned a high score (5.0) to items that were clicked and a low score (1.0) to those that weren't. This binary scoring method was the foundation of our early models.\n",
    "\n",
    "    - Adapting to Dataset Limitations: Unlike datasets used in typical tutorials, where users have provided explicit ratings for the items they interact with, our competition dataset lacked such explicit user ratings. To address this, we self-assigned ratings to each interaction during the data collection phase from the test environment. This allowed us to simulate a scenario with explicit user preferences and enhance the effectiveness of our recommendation models.\n",
    "\n",
    "    - Experiment with Soft Labels: In an attempt to refine our model's accuracy, we experimented with soft labels instead of binary scores. The idea was to incorporate varying degrees of preference rather than a strict clicked/unclicked dichotomy. However, due to time constraints and complexity in implementation, we reverted to using only clicked data (score 5.0) for our final submissions. Interestingly, we found that the performance did not significantly differ from the more nuanced approach.\n",
    "\n",
    "    - Hyperparameter tuning: After rigorous experimentation, we found the following set of hyperparameters to yield the best performance: EMBEDDING_SIZE = 512, BATCH_SIZE = 128, N_EPOCHS = 20, LEARNING_RATE = 1e-5.\n",
    "\n",
    "### III. Discussions\n",
    "In this competition, the lack of substantial interaction data presented a significant challenge. Merely adjusting the model without considering other methods to potentially improve performance, or without collecting more data, made it difficult to achieve desirable results. The process of data augmentation also posed its own set of challenges; it wasn't just about recording which users clicked on which items, but also about designing a mechanism for user ratings. Despite collecting more interaction data from both the training and testing environments, making accurate recommendations for the latter 1,000 users during testing was particularly challenging due to the scarcity of data available from the training phase. This issue adversely affected our final ranking. Thus, how to ensure that all users receive good recommendations and how to effectively rate interactions based on user behavior remain critical questions for us to consider.\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
